{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T04:33:57.212451Z",
     "start_time": "2025-09-30T04:33:54.185274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from outlines.models import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import transformers\n"
   ],
   "id": "d42f776961f8a676",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T04:39:38.281241Z",
     "start_time": "2025-09-30T04:39:38.276996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_anneal_attn_mask(seq_len, bsz, dtype, device, attn_mask_ratio):\n",
    "    mask = torch.full((seq_len, seq_len), 0, device=device)\n",
    "    mask_cond = torch.arange(mask.size(-1), device=device)\n",
    "    mask.masked_fill_(mask_cond < (mask_cond + 1).view(mask.size(-1), 1), 1)\n",
    "    causal_mask = mask.to(dtype)\n",
    "\n",
    "    random_mask = torch.bernoulli(torch.full((seq_len, seq_len), 0.0, device=device) + attn_mask_ratio)\n",
    "\n",
    "    anneal_mask = torch.logical_or(causal_mask, random_mask)\n",
    "    expanded_mask = anneal_mask[None, None, :, :].expand(bsz, 1, seq_len, seq_len)\n",
    "    inverted_mask = 1.0 - expanded_mask.to(dtype)\n",
    "\n",
    "    return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)\n"
   ],
   "id": "6f8528ad4aa2ebbd",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T04:33:57.227675Z",
     "start_time": "2025-09-30T04:33:57.219430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# looks like Qwen using SDPA should be fine with an adapted attention mask, no\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "from transformers import DynamicCache\n",
    "from transformers.processing_utils import Unpack\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPast\n",
    "from transformers.modeling_flash_attention_utils import FlashAttentionKwargs\n",
    "from cachetools import Cache\n",
    "from typing import Optional, __all__\n",
    "from transformers.utils import logging\n",
    "\n",
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "\n",
    "def qwen_new_forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        past_key_values: Optional[Cache] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        cache_position: Optional[torch.LongTensor] = None,\n",
    "        **flash_attn_kwargs: Unpack[FlashAttentionKwargs],\n",
    ") -> BaseModelOutputWithPast:\n",
    "    output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "    output_hidden_states = (\n",
    "        output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "    )\n",
    "    use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
    "\n",
    "    if (input_ids is None) ^ (inputs_embeds is not None):\n",
    "        raise ValueError(\"You must specify exactly one of input_ids or inputs_embeds\")\n",
    "\n",
    "    if self.gradient_checkpointing and self.training and use_cache:\n",
    "        logger.warning_once(\n",
    "            \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\"\n",
    "        )\n",
    "        use_cache = False\n",
    "\n",
    "    # TODO (joao): remove this exception in v4.56 -- it exists for users that try to pass a legacy cache\n",
    "    if not isinstance(past_key_values, (type(None), Cache)):\n",
    "        raise ValueError(\"The `past_key_values` should be either a `Cache` object or `None`.\")\n",
    "\n",
    "    if inputs_embeds is None:\n",
    "        inputs_embeds = self.embed_tokens(input_ids)\n",
    "\n",
    "    if use_cache and past_key_values is None:\n",
    "        past_key_values = DynamicCache()\n",
    "\n",
    "    if cache_position is None:\n",
    "        past_seen_tokens = past_key_values.get_seq_length() if past_key_values is not None else 0\n",
    "        cache_position = torch.arange(\n",
    "            past_seen_tokens, past_seen_tokens + inputs_embeds.shape[1], device=inputs_embeds.device\n",
    "        )\n",
    "\n",
    "    if position_ids is None:\n",
    "        position_ids = cache_position.unsqueeze(0)\n",
    "\n",
    "    ## Add by DiffuLLaMA, adapting for 4d attention-mask.\n",
    "    if attention_mask is not None and len(attention_mask.shape) == 4:\n",
    "        causal_mask = attention_mask\n",
    "        print(\"logging....attention-mask for 4d\")\n",
    "    else:\n",
    "        causal_mask = self._update_causal_mask(\n",
    "            attention_mask, inputs_embeds, cache_position, past_key_values, output_attentions\n",
    "        )\n",
    "\n",
    "    print(causal_mask)\n",
    "\n",
    "    # causal_mask = self._update_causal_mask(\n",
    "    #     attention_mask, inputs_embeds, cache_position, past_key_values, output_attentions\n",
    "    # )\n",
    "\n",
    "    hidden_states = inputs_embeds\n",
    "\n",
    "    # create position embeddings to be shared across the decoder layers\n",
    "    position_embeddings = self.rotary_emb(hidden_states, position_ids)\n",
    "\n",
    "    # decoder layers\n",
    "    all_hidden_states = () if output_hidden_states else None\n",
    "    all_self_attns = () if output_attentions else None\n",
    "\n",
    "    for decoder_layer in self.layers[: self.config.num_hidden_layers]:\n",
    "        if output_hidden_states:\n",
    "            all_hidden_states += (hidden_states,)\n",
    "\n",
    "        if self.gradient_checkpointing and self.training:\n",
    "            layer_outputs = self._gradient_checkpointing_func(\n",
    "                partial(decoder_layer.__call__, **flash_attn_kwargs),\n",
    "                hidden_states,\n",
    "                causal_mask,\n",
    "                position_ids,\n",
    "                past_key_values,\n",
    "                output_attentions,\n",
    "                use_cache,\n",
    "                cache_position,\n",
    "                position_embeddings,\n",
    "            )\n",
    "        else:\n",
    "            layer_outputs = decoder_layer(\n",
    "                hidden_states,\n",
    "                attention_mask=causal_mask,\n",
    "                position_ids=position_ids,\n",
    "                past_key_value=past_key_values,\n",
    "                output_attentions=output_attentions,\n",
    "                use_cache=use_cache,\n",
    "                cache_position=cache_position,\n",
    "                position_embeddings=position_embeddings,\n",
    "                **flash_attn_kwargs,\n",
    "            )\n",
    "\n",
    "        hidden_states = layer_outputs[0]\n",
    "\n",
    "        if output_attentions:\n",
    "            all_self_attns += (layer_outputs[1],)\n",
    "\n",
    "    hidden_states = self.norm(hidden_states)\n",
    "\n",
    "    # add hidden states from the last decoder layer\n",
    "    if output_hidden_states:\n",
    "        all_hidden_states += (hidden_states,)\n",
    "\n",
    "    return BaseModelOutputWithPast(\n",
    "        last_hidden_state=hidden_states,\n",
    "        past_key_values=past_key_values if use_cache else None,\n",
    "        hidden_states=all_hidden_states,\n",
    "        attentions=all_self_attns,\n",
    "    )\n"
   ],
   "id": "957aab8657358189",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T04:33:58.480802Z",
     "start_time": "2025-09-30T04:33:57.272881Z"
    }
   },
   "cell_type": "code",
   "source": "transformers.models.qwen3.modeling_qwen3.Qwen3Model.forward = qwen_new_forward",
   "id": "dee98ee1bb785d2b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-30 14:03:57,542] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sean/miniconda3/envs/goedelv2/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/sean/miniconda3/envs/goedelv2/compiler_compat/ld: cannot find -lcufile: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T04:34:02.446547Z",
     "start_time": "2025-09-30T04:34:00.935200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_id = \"Goedel-LM/Goedel-Prover-V2-8B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, trust_remote_code=True)\n"
   ],
   "id": "2276d415d49ebe71",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 28.36it/s]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T04:37:11.113742Z",
     "start_time": "2025-09-30T04:37:11.109113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "formal_statement = \"\"\"\n",
    "import Mathlib\n",
    "import Aesop\n",
    "\n",
    "set_option maxHeartbeats 0\n",
    "\n",
    "open BigOperators Real Nat Topology Rat\n",
    "\n",
    "\n",
    "theorem square_equation_solution {x y : ℝ} (h : x^2 + y^2 = 2*x - 4*y - 5) : x + y = -1 := by\n",
    "  sorry\n",
    "\"\"\".strip()\n",
    "\n",
    "prompt = \"\"\"\n",
    "Complete the following Lean 4 code:\n",
    "\n",
    "```lean4\n",
    "{}```\n",
    "\n",
    "Before producing the Lean 4 code to formally prove the given theorem, provide a detailed proof plan outlining the main proof steps and strategies.\n",
    "The plan should highlight key ideas, intermediate lemmas, and proof structures that will guide the construction of the final formal proof.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat = [\n",
    "    [{\"role\": \"user\", \"content\": 'ABC'}],\n",
    "    [{'role': 'user', 'content': 'ABCDEF'}]\n",
    "]\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(chat, tokenize=True, add_generation_prompt=True, padding='longest',\n",
    "                                       return_dict=True, return_tensors='pt')"
   ],
   "id": "a259e83822c572f0",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T04:37:11.730049Z",
     "start_time": "2025-09-30T04:37:11.725602Z"
    }
   },
   "cell_type": "code",
   "source": "inputs",
   "id": "abdca33fdc59c9b3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[151644,    872,    198,  25411, 151645,    198, 151644,  77091,    198,\n",
       "         151643],\n",
       "        [151644,    872,    198,  25411,  13649, 151645,    198, 151644,  77091,\n",
       "            198]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T04:37:35.464982Z",
     "start_time": "2025-09-30T04:37:35.460792Z"
    }
   },
   "cell_type": "code",
   "source": "inputs['attention_mask']",
   "id": "b056ff85f40366a8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T04:37:36.780627Z",
     "start_time": "2025-09-30T04:37:36.461368Z"
    }
   },
   "cell_type": "code",
   "source": "model.forward(inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
   "id": "8d3b4a1cce910ee2",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "           -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38],\n",
      "          [-0.0000e+00, -0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "           -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38],\n",
      "          [-0.0000e+00, -0.0000e+00, -0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "           -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38],\n",
      "          [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -3.3895e+38,\n",
      "           -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38],\n",
      "          [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "           -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38],\n",
      "          [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "           -0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38],\n",
      "          [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "           -0.0000e+00, -0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38],\n",
      "          [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "           -0.0000e+00, -0.0000e+00, -0.0000e+00, -3.3895e+38, -3.3895e+38],\n",
      "          [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "           -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -3.3895e+38],\n",
      "          [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "           -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -3.3895e+38]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "           -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38],\n",
      "          [-0.0000e+00, -0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "           -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38],\n",
      "          [-0.0000e+00, -0.0000e+00, -0.0000e+00, -3.3895e+38, -3.3895e+38,\n",
      "           -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38],\n",
      "          [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -3.3895e+38,\n",
      "           -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38],\n",
      "          [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "           -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38],\n",
      "          [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "           -0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38],\n",
      "          [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "           -0.0000e+00, -0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38],\n",
      "          [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "           -0.0000e+00, -0.0000e+00, -0.0000e+00, -3.3895e+38, -3.3895e+38],\n",
      "          [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "           -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -3.3895e+38],\n",
      "          [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
      "           -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00]]]],\n",
      "       dtype=torch.bfloat16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithPast(loss=None, logits=tensor([[[ 2.5938e+00,  1.9922e+00,  1.2891e+00,  ..., -4.4727e-01,\n",
       "          -4.4727e-01, -4.4727e-01],\n",
       "         [ 9.1875e+00,  1.0875e+01,  8.7500e+00,  ...,  4.3030e-03,\n",
       "           4.3030e-03,  4.3335e-03],\n",
       "         [ 1.4141e+00,  7.2500e+00,  8.5625e+00,  ..., -1.8164e-01,\n",
       "          -1.8164e-01, -1.8164e-01],\n",
       "         ...,\n",
       "         [ 4.5938e+00,  2.9844e+00,  4.7188e+00,  ..., -1.2390e-02,\n",
       "          -1.2390e-02, -1.2390e-02],\n",
       "         [ 8.1875e+00,  7.2812e+00,  9.2500e+00,  ...,  1.2891e-01,\n",
       "           1.2891e-01,  1.2891e-01],\n",
       "         [ 6.0312e+00,  3.8906e+00,  9.1250e+00,  ...,  1.2012e-01,\n",
       "           1.2012e-01,  1.2012e-01]],\n",
       "\n",
       "        [[ 2.5938e+00,  1.9922e+00,  1.2891e+00,  ..., -4.4727e-01,\n",
       "          -4.4727e-01, -4.4727e-01],\n",
       "         [ 9.1875e+00,  1.0875e+01,  8.7500e+00,  ...,  4.3030e-03,\n",
       "           4.3030e-03,  4.3335e-03],\n",
       "         [ 1.4141e+00,  7.2500e+00,  8.5625e+00,  ..., -1.8164e-01,\n",
       "          -1.8164e-01, -1.8164e-01],\n",
       "         ...,\n",
       "         [ 3.9688e+00,  3.9531e+00,  2.7500e+00,  ..., -2.3281e+00,\n",
       "          -2.3281e+00, -2.3281e+00],\n",
       "         [ 4.2188e+00,  2.9531e+00,  4.6250e+00,  ..., -2.3828e-01,\n",
       "          -2.3828e-01, -2.3828e-01],\n",
       "         [ 8.5625e+00,  7.9688e+00,  8.9375e+00,  ..., -1.7578e-01,\n",
       "          -1.7578e-01, -1.7578e-01]]], dtype=torch.bfloat16,\n",
       "       grad_fn=<UnsafeViewBackward0>), past_key_values=None, hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T04:41:43.822962Z",
     "start_time": "2025-09-30T04:41:43.810284Z"
    }
   },
   "cell_type": "code",
   "source": "attn_mask = get_anneal_attn_mask(inputs['input_ids'].shape[1], inputs['input_ids'].shape[0], dtype=torch.bfloat16, device=inputs['input_ids'].device, attn_mask_ratio=0.5)",
   "id": "b5efd98a9cd53245",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T04:42:55.856581Z",
     "start_time": "2025-09-30T04:42:55.556053Z"
    }
   },
   "cell_type": "code",
   "source": "logits = model.forward(inputs['input_ids'], attention_mask=attn_mask)",
   "id": "61ba65cbcd545a83",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging....attention-mask for 4d\n",
      "tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "           -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,  0.0000e+00,\n",
      "            0.0000e+00, -3.3895e+38, -3.3895e+38,  0.0000e+00, -3.3895e+38],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           -3.3895e+38,  0.0000e+00,  0.0000e+00, -3.3895e+38,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,\n",
      "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00, -3.3895e+38, -3.3895e+38, -3.3895e+38,\n",
      "           -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,  0.0000e+00,\n",
      "            0.0000e+00, -3.3895e+38, -3.3895e+38,  0.0000e+00, -3.3895e+38],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38, -3.3895e+38],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           -3.3895e+38,  0.0000e+00,  0.0000e+00, -3.3895e+38,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00,  0.0000e+00, -3.3895e+38,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]]],\n",
      "       dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# todo:\n",
    "# -"
   ],
   "id": "f9e2ddcf8ad3a982"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
